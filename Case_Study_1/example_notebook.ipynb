{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for exploring tranformer model\n",
    "\n",
    "The pretrained model is a hugging face timeseries transformer. See the links below for more informaiton.\n",
    "* documentation: https://huggingface.co/docs/transformers/main/model_doc/time_series_transformer\n",
    "* blog: https://huggingface.co/blog/time-series-transformers\n",
    "* copy of notebook: https://colab.research.google.com/drive/1ZxSBXtSx4hYBFheeCsWAaOZEdDnnobL-\n",
    "  \n",
    "\n",
    "This transformer models the monthly tourism volumes for 366 regions in Austrailia. The transfromer is trained with the following parameters:\n",
    "* prediction_length = 2\n",
    "* context_length = 2 \n",
    "* activatio_function='relu' (changed from gelu to relu)\n",
    "* embedding_dimension=[2]  (trained on data for 366 distinct time series)\n",
    "* encoder_layers=4\n",
    "* decoder_layers=4\n",
    "* d_model=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sian_\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TimeSeriesTransformerModel\n",
    "\n",
    "model = TimeSeriesTransformerModel.from_pretrained(\"timeseries_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: embedder.embedders.0.weight | Size: torch.Size([366, 2]) | Values : tensor([[ 0.0291, -0.0173],\n",
      "        [ 0.1960,  0.1804]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.value_embedding.value_projection.weight | Size: torch.Size([32, 22]) | Values : tensor([[ 0.0495,  0.3958,  0.0074,  0.0078,  0.0243,  0.0162, -0.0036,  0.0165,\n",
      "         -0.0073, -0.0221,  0.0197, -0.0033,  0.0267, -0.0100,  0.0061, -0.0276,\n",
      "          0.3031,  0.5288,  0.0084, -0.0425, -0.0334,  0.0728],\n",
      "        [-0.1568, -0.0855,  0.0044, -0.0016, -0.0152, -0.0126, -0.0075, -0.0034,\n",
      "         -0.0173, -0.0071, -0.0187,  0.0200,  0.0080, -0.0103,  0.0109,  0.0145,\n",
      "         -0.5038, -0.3136,  0.0143, -0.0100,  0.1091, -0.0559]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.embed_positions.weight | Size: torch.Size([6, 32]) | Values : tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [8.4147e-01, 5.3317e-01, 3.1098e-01, 1.7689e-01, 9.9833e-02, 5.6204e-02,\n",
      "         3.1618e-02, 1.7782e-02, 9.9998e-03, 5.6234e-03, 3.1623e-03, 1.7783e-03,\n",
      "         1.0000e-03, 5.6234e-04, 3.1623e-04, 1.7783e-04, 5.4030e-01, 8.4601e-01,\n",
      "         9.5042e-01, 9.8423e-01, 9.9500e-01, 9.9842e-01, 9.9950e-01, 9.9984e-01,\n",
      "         9.9995e-01, 9.9998e-01, 9.9999e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00]]) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0711, -0.0089, -0.0576,  0.0126, -0.0318,  0.0170, -0.0085, -0.0088,\n",
      "         -0.0361, -0.0865, -0.0201, -0.0364,  0.0055, -0.0541, -0.0520,  0.0330,\n",
      "         -0.0083,  0.0480,  0.0291, -0.0538, -0.0273,  0.0092,  0.0341, -0.0535,\n",
      "         -0.0032,  0.0412,  0.0665,  0.0177,  0.0335, -0.0142,  0.0434,  0.0408],\n",
      "        [-0.0673, -0.0392, -0.0568,  0.0282, -0.0631,  0.0218,  0.0120, -0.0032,\n",
      "         -0.0223, -0.0472, -0.0640, -0.0259,  0.0015, -0.0869, -0.0638,  0.0045,\n",
      "          0.0160,  0.0434,  0.0683, -0.0462, -0.0239,  0.0159,  0.0327, -0.0245,\n",
      "          0.0279,  0.0211,  0.0412,  0.0109, -0.0134, -0.0294,  0.0316,  0.0153]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0007, -0.0004], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0129, -0.0194, -0.0063, -0.0018, -0.0373,  0.0044,  0.0611,  0.0470,\n",
      "          0.0231,  0.0373, -0.0121,  0.0177,  0.0208,  0.0326, -0.0146,  0.0313,\n",
      "          0.0215, -0.0164,  0.0085, -0.0195, -0.0730, -0.1504,  0.0108,  0.0037,\n",
      "         -0.0076,  0.0058, -0.0500, -0.0578,  0.0067,  0.0371, -0.0064, -0.0718],\n",
      "        [ 0.0301, -0.0157, -0.0192, -0.0157,  0.0091,  0.0032,  0.0390,  0.0112,\n",
      "         -0.0036,  0.0217, -0.0006, -0.0100, -0.0180, -0.0193,  0.0202,  0.0202,\n",
      "          0.0323,  0.0057,  0.0056,  0.0178, -0.0025,  0.0509,  0.0059, -0.0269,\n",
      "         -0.0002, -0.0345,  0.0218,  0.0318,  0.0390, -0.0468,  0.0072,  0.0171]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0002, -0.0105], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0373,  0.1133, -0.0607, -0.0401, -0.0520, -0.0915, -0.0264, -0.0502,\n",
      "         -0.0487, -0.0815, -0.0485, -0.0638, -0.0567, -0.0689, -0.0511, -0.0607,\n",
      "          0.0039, -0.0296,  0.0706,  0.1521,  0.2123,  0.1724,  0.0589,  0.0678,\n",
      "          0.0334,  0.0619,  0.0902,  0.1034,  0.0567,  0.0564,  0.0686,  0.1609],\n",
      "        [-0.0585,  0.0414, -0.0186, -0.0304, -0.0215, -0.0561, -0.0228, -0.0528,\n",
      "          0.0024, -0.0473, -0.0177, -0.0248, -0.0277, -0.0158, -0.0538, -0.0613,\n",
      "         -0.0056, -0.0080,  0.0394,  0.1473,  0.1375,  0.2251,  0.0062,  0.0249,\n",
      "          0.0215,  0.0607,  0.1115,  0.0961,  0.0085,  0.0533,  0.0467,  0.1055]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0447, 0.0186], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0224, -0.0578,  0.0036,  0.0502, -0.0230, -0.0018,  0.0143,  0.0608,\n",
      "          0.0093, -0.0053, -0.0671, -0.0380,  0.0821,  0.0493,  0.0436, -0.0275,\n",
      "         -0.0069,  0.0363, -0.0708,  0.0023, -0.0129, -0.0304,  0.0520,  0.0540,\n",
      "         -0.0130,  0.0391,  0.0208,  0.0032,  0.0603,  0.0016,  0.0095,  0.0268],\n",
      "        [-0.0113,  0.0410,  0.0530, -0.0628,  0.0002,  0.0368,  0.0259, -0.0138,\n",
      "         -0.0215,  0.0249,  0.0479,  0.0118, -0.1016, -0.0163, -0.0170, -0.0011,\n",
      "          0.0182,  0.0208, -0.0014, -0.0160, -0.0248, -0.0156, -0.0075, -0.0290,\n",
      "         -0.0240, -0.0706, -0.0558,  0.0036,  0.0097,  0.0346, -0.0113,  0.0189]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0139, 0.0033], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7804, 0.7712], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.self_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0316, 0.0008], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.fc1.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0875,  0.0493,  0.0798, -0.0606,  0.0517, -0.0653, -0.1138, -0.0540,\n",
      "          0.0495, -0.0944,  0.0294,  0.0220, -0.0874,  0.0391,  0.0265, -0.1285,\n",
      "         -0.0087,  0.1654, -0.0387,  0.0689,  0.1106,  0.1355, -0.0725,  0.0810,\n",
      "         -0.0471, -0.0836,  0.0352,  0.0724, -0.0970,  0.0323, -0.0338,  0.0551],\n",
      "        [-0.0401, -0.0077,  0.0195, -0.0590,  0.0206, -0.0614, -0.0790, -0.0261,\n",
      "          0.0134, -0.0934, -0.0149, -0.0265, -0.0208, -0.0153, -0.0107, -0.0618,\n",
      "         -0.0022, -0.0086, -0.0361,  0.0425,  0.0510,  0.1306,  0.0036, -0.0103,\n",
      "         -0.0049, -0.0281,  0.0409,  0.0343, -0.0016,  0.0408, -0.0003,  0.0511]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.fc1.bias | Size: torch.Size([32]) | Values : tensor([-0.0328,  0.0083], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.fc2.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0091,  0.0524, -0.0234,  0.0180, -0.0333, -0.0323, -0.0307, -0.0124,\n",
      "          0.0503, -0.1077, -0.0235,  0.0411,  0.1326,  0.1044,  0.0076, -0.5324,\n",
      "          0.0120, -0.0821, -0.0439,  0.0100, -0.0641,  0.0517,  0.0159,  0.0418,\n",
      "         -0.1543, -0.0013,  0.0217, -0.0422, -0.0104,  0.0435, -0.1879,  0.0089],\n",
      "        [ 0.0693, -0.0650,  0.0036,  0.1626, -0.0274,  0.0490,  0.0301, -0.0391,\n",
      "          0.2243, -0.1339,  0.0805,  0.0061, -0.1069, -0.0587, -0.0365, -0.3648,\n",
      "         -0.0530,  0.1075,  0.0524, -0.0156, -0.1013,  0.0095,  0.1853,  0.1163,\n",
      "         -0.2627,  0.0130,  0.0720, -0.1681, -0.0381,  0.0664,  0.0320, -0.0084]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.fc2.bias | Size: torch.Size([32]) | Values : tensor([ 0.0406, -0.0070], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.final_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7891, 0.7746], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.0.final_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([4.8256e-02, 8.7019e-05], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.1694, -0.0021,  0.0321, -0.0172, -0.0309, -0.0422, -0.0587, -0.0666,\n",
      "         -0.0020, -0.0910,  0.0028, -0.0812, -0.0637, -0.0144,  0.0159, -0.0552,\n",
      "         -0.0080,  0.0336, -0.0154,  0.0239,  0.0151,  0.0693, -0.0350, -0.0267,\n",
      "         -0.0375, -0.0726,  0.0806,  0.0207, -0.0174, -0.0190,  0.0021,  0.0272],\n",
      "        [ 0.0682,  0.0218, -0.0023, -0.0589,  0.0059, -0.0721, -0.0290, -0.0288,\n",
      "         -0.0108, -0.1038,  0.0124, -0.0043,  0.0223,  0.0864,  0.0823, -0.0034,\n",
      "          0.0282, -0.0142, -0.0116,  0.0864, -0.0043, -0.1236, -0.0283, -0.0363,\n",
      "          0.0352,  0.0199,  0.0052,  0.0439,  0.0263,  0.1531, -0.0781, -0.0223]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([ 1.7362e-04, -3.0216e-05], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0035, -0.0689,  0.0113,  0.0058, -0.0046, -0.0260, -0.0476, -0.0037,\n",
      "         -0.0128, -0.0342,  0.0294, -0.0422,  0.0343,  0.0126, -0.0201, -0.0109,\n",
      "          0.0757,  0.0273,  0.0213,  0.0136,  0.0123,  0.0374, -0.0030, -0.0275,\n",
      "         -0.0104, -0.0116, -0.0111, -0.0281, -0.0099, -0.0123, -0.0031,  0.0359],\n",
      "        [ 0.0122, -0.0072, -0.0056, -0.0655, -0.0027, -0.0466,  0.0340, -0.0023,\n",
      "         -0.0044, -0.0068, -0.0082,  0.0047, -0.0714, -0.0280, -0.0059,  0.0271,\n",
      "          0.0385,  0.0096,  0.0164,  0.0159,  0.0029,  0.0364, -0.0203,  0.0101,\n",
      "         -0.0232, -0.0347,  0.0594,  0.0646,  0.0135,  0.0081,  0.0224,  0.0026]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0170,  0.0015], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0360,  0.0836,  0.0794,  0.0973,  0.0761,  0.0206,  0.0057,  0.0625,\n",
      "          0.0533, -0.0711,  0.0389,  0.0487, -0.0266,  0.0197,  0.0545,  0.0285,\n",
      "         -0.1144, -0.0235, -0.0895, -0.0051,  0.0682,  0.1119, -0.0505, -0.0548,\n",
      "         -0.0379, -0.0720,  0.0204,  0.0459, -0.0478,  0.0006, -0.0414,  0.0332],\n",
      "        [ 0.0026,  0.0029, -0.0028,  0.1157,  0.0131,  0.1060,  0.1625,  0.0794,\n",
      "          0.0067,  0.1161, -0.0054,  0.0561,  0.0681, -0.0125, -0.0142,  0.1719,\n",
      "         -0.0027, -0.0518,  0.0091, -0.1433, -0.1316, -0.1780,  0.0357,  0.0120,\n",
      "         -0.0193,  0.0395, -0.0630, -0.0992,  0.0216, -0.0373, -0.0179, -0.0762]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0519,  0.0013], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0715,  0.0328,  0.0326,  0.0008, -0.0320,  0.0140,  0.0257, -0.0148,\n",
      "         -0.0171,  0.0578, -0.0589,  0.0057, -0.0207, -0.0440, -0.0187, -0.0394,\n",
      "          0.0252,  0.0170, -0.0038, -0.0378,  0.0241, -0.0099,  0.0647, -0.0270,\n",
      "         -0.0391, -0.0209,  0.0137,  0.0213,  0.0271,  0.0071,  0.0115,  0.0661],\n",
      "        [ 0.0852, -0.0348, -0.0370,  0.0465, -0.0109,  0.0020, -0.0336,  0.0579,\n",
      "          0.0396, -0.0478,  0.0703, -0.0083,  0.0114,  0.0002,  0.0811,  0.0406,\n",
      "         -0.0427, -0.0018,  0.0144,  0.0181, -0.0613, -0.0111, -0.0935,  0.0237,\n",
      "          0.0277,  0.0202,  0.0194,  0.0232, -0.0410,  0.0308, -0.0408, -0.0663]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0218, 0.0027], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7805, 0.7735], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.self_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0285, 0.0049], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.fc1.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0146, -0.0177,  0.0867, -0.0097, -0.0381,  0.0190,  0.0064,  0.0012,\n",
      "         -0.0140,  0.0008,  0.0015, -0.0133,  0.0393,  0.0062,  0.0046,  0.0141,\n",
      "          0.0020,  0.0596,  0.0421, -0.0046, -0.0632, -0.0735, -0.0519,  0.0446,\n",
      "          0.0022,  0.0262, -0.0577, -0.0600,  0.0495, -0.0068, -0.0136, -0.0465],\n",
      "        [ 0.0369, -0.0043,  0.0215, -0.0174,  0.0265, -0.0260, -0.0421, -0.0017,\n",
      "          0.0198, -0.1945,  0.0074, -0.0771, -0.0188,  0.0006,  0.0024, -0.0273,\n",
      "         -0.0028,  0.0800, -0.0025,  0.0480,  0.0389,  0.0974, -0.0306, -0.0496,\n",
      "         -0.0174, -0.0203,  0.0491,  0.0354,  0.0061, -0.0499,  0.0057,  0.0501]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.fc1.bias | Size: torch.Size([32]) | Values : tensor([-0.0061, -0.0043], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.fc2.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.1081, -0.0748, -0.1893, -0.1196,  0.0113, -0.0008,  0.0511,  0.0375,\n",
      "         -0.0321,  0.0024,  0.1257, -0.0853,  0.1481, -0.0253, -0.0531, -0.1053,\n",
      "          0.0173, -0.1688, -0.0279,  0.0175,  0.0333, -0.0419, -0.0136, -0.0382,\n",
      "         -0.0784,  0.0336,  0.1261,  0.0248, -0.0344,  0.0068, -0.0885,  0.1064],\n",
      "        [ 0.0374,  0.0182, -0.2088, -0.1629, -0.0192,  0.1256,  0.0616, -0.0621,\n",
      "         -0.1371,  0.1275,  0.0382, -0.1686,  0.0469, -0.0366, -0.1486,  0.0958,\n",
      "         -0.0751,  0.1188, -0.0011,  0.0276,  0.0831, -0.0652, -0.0177,  0.1722,\n",
      "          0.1566, -0.0412, -0.0042, -0.0986, -0.0688, -0.0391, -0.0910,  0.0231]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.fc2.bias | Size: torch.Size([32]) | Values : tensor([0.0343, 0.0051], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.final_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7909, 0.7860], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.1.final_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0379, 0.0102], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-2.4578e-02,  3.8141e-02, -4.1647e-02,  5.2262e-02, -3.7778e-02,\n",
      "          3.2797e-02,  8.4933e-03, -1.3459e-02,  2.9587e-02, -7.8840e-03,\n",
      "         -3.6621e-02, -3.2437e-02, -6.1472e-03, -5.9222e-03, -1.4780e-02,\n",
      "         -2.5881e-02, -1.9870e-02,  1.1884e-02,  1.8949e-02, -4.2655e-02,\n",
      "         -2.0934e-02, -2.9909e-02,  5.5081e-02,  1.9075e-02,  4.0666e-02,\n",
      "          9.0064e-05,  1.6561e-02,  5.4899e-02, -8.6430e-02,  3.0403e-03,\n",
      "          2.4835e-02,  1.1668e-02],\n",
      "        [-9.6321e-02, -2.2734e-02,  2.9888e-02, -4.1445e-03,  7.0510e-02,\n",
      "         -4.4737e-02,  2.1699e-02,  4.2635e-02,  3.3470e-02,  3.1445e-02,\n",
      "          4.3739e-02,  5.7706e-02,  4.4858e-02,  9.1711e-02,  5.5154e-02,\n",
      "          4.9378e-02, -8.5814e-03, -2.0260e-02, -3.9730e-02,  4.7843e-02,\n",
      "          1.7558e-02, -2.9515e-02, -5.4244e-02, -1.5038e-02, -1.1243e-02,\n",
      "          7.8167e-02, -7.8977e-04, -5.4649e-02,  4.0751e-02,  3.5245e-02,\n",
      "         -4.8709e-02,  9.3162e-03]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([-7.9332e-05,  3.3465e-05], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 4.9402e-02,  2.1842e-02,  9.4324e-03, -2.2985e-02,  1.1418e-02,\n",
      "          1.0474e-02,  1.1184e-03,  1.3578e-02, -4.7396e-03, -6.2075e-03,\n",
      "         -2.1315e-02, -3.4937e-02, -3.1106e-02, -2.1240e-02,  2.0511e-03,\n",
      "          7.7702e-05, -9.7681e-02,  1.0076e-02, -1.4468e-02, -2.5145e-02,\n",
      "         -4.2302e-02, -2.3767e-02,  1.4960e-02,  2.6341e-02,  1.2101e-02,\n",
      "          9.0370e-04, -4.1892e-02, -2.7649e-02,  2.1394e-02,  3.7902e-02,\n",
      "          1.7907e-02, -3.8219e-02],\n",
      "        [ 8.6818e-03,  1.0767e-02, -2.8233e-03, -7.4947e-02,  1.3076e-02,\n",
      "         -3.5263e-02, -2.1255e-02, -2.0534e-02,  5.7717e-03, -4.7839e-02,\n",
      "         -3.5361e-02, -1.9725e-02, -3.7308e-02,  9.6435e-03,  1.6885e-02,\n",
      "         -6.1101e-02,  1.9763e-02,  9.4842e-03, -6.4304e-03,  1.8009e-02,\n",
      "          3.5378e-02,  7.9677e-02,  1.6778e-02,  2.0652e-02,  3.0653e-03,\n",
      "          9.5039e-03,  2.0536e-02,  4.7428e-02, -1.0019e-02, -3.8479e-02,\n",
      "          1.6330e-02,  4.2902e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0079, 0.0073], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0434, -0.0123,  0.0497, -0.0606,  0.0081, -0.0184, -0.0963, -0.0356,\n",
      "         -0.0216, -0.0197,  0.0493,  0.0107, -0.0039, -0.0112, -0.0222, -0.0799,\n",
      "         -0.0081, -0.0043, -0.0153,  0.0829,  0.0681,  0.0292, -0.0236, -0.0225,\n",
      "         -0.0320,  0.0272,  0.0288,  0.0445,  0.0346, -0.0653,  0.0047,  0.0622],\n",
      "        [ 0.0402,  0.0116, -0.0083,  0.0425, -0.0573,  0.0419,  0.0863,  0.0005,\n",
      "         -0.0020,  0.0701,  0.0043,  0.0121,  0.0623, -0.0138,  0.0073,  0.0530,\n",
      "          0.0258, -0.0210,  0.0198, -0.0512, -0.1441, -0.1674,  0.0256,  0.0321,\n",
      "          0.0424,  0.0177, -0.0385, -0.0313,  0.0216,  0.0318, -0.0160, -0.0624]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0084, 0.0135], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0280, -0.0149, -0.0003, -0.0134, -0.0074,  0.0039,  0.0744,  0.0275,\n",
      "          0.0466,  0.0124, -0.0407,  0.0013, -0.0018,  0.0368,  0.0346, -0.0694,\n",
      "          0.0098, -0.0010, -0.0379, -0.0318,  0.0128,  0.0136,  0.0220, -0.0474,\n",
      "         -0.0323,  0.0225,  0.0680,  0.0161,  0.0260, -0.0061,  0.0380,  0.0133],\n",
      "        [-0.0270, -0.0067, -0.0791, -0.0014, -0.0116, -0.0264, -0.0708, -0.0039,\n",
      "         -0.0242, -0.0402,  0.0468,  0.0181,  0.0172, -0.0348, -0.0301,  0.0237,\n",
      "          0.0406, -0.0114,  0.0339,  0.0571, -0.0261, -0.0368, -0.0574,  0.0648,\n",
      "          0.0596, -0.0130, -0.0241, -0.0413, -0.0647,  0.0349, -0.0541, -0.0115]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0324, 0.0013], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7867, 0.7776], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.self_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0395, 0.0164], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.fc1.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0028, -0.0200, -0.0579, -0.1647, -0.0446, -0.0344,  0.0223,  0.0037,\n",
      "         -0.0154,  0.0774,  0.0144, -0.0034,  0.0083,  0.1083,  0.0413,  0.0241,\n",
      "          0.0117,  0.0180, -0.0121,  0.0496, -0.0788, -0.1114, -0.0013,  0.0070,\n",
      "          0.0066, -0.0301,  0.0008,  0.0496,  0.0043,  0.0381, -0.1159, -0.0669],\n",
      "        [-0.0045, -0.0208,  0.0728, -0.0865,  0.0434, -0.0399, -0.0958, -0.0413,\n",
      "          0.0233, -0.1662,  0.0605, -0.0801,  0.0374,  0.0006,  0.0164, -0.0695,\n",
      "         -0.0316, -0.0091, -0.0088,  0.1752,  0.0722,  0.0256, -0.0204, -0.0298,\n",
      "         -0.0178, -0.0075,  0.0283,  0.0318,  0.0094, -0.0197,  0.0119,  0.0117]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.fc1.bias | Size: torch.Size([32]) | Values : tensor([-0.0261,  0.0125], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.fc2.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0658, -0.0852,  0.0864, -0.1479,  0.0181, -0.0420, -0.1093, -0.0493,\n",
      "         -0.0771, -0.0574,  0.0326,  0.0299,  0.0166, -0.1192,  0.0432,  0.0019,\n",
      "         -0.1605,  0.0544,  0.0135, -0.1007, -0.0087,  0.0464, -0.1593, -0.0093,\n",
      "         -0.0438,  0.1521,  0.0401, -0.0775,  0.2023, -0.1661,  0.1747,  0.0195],\n",
      "        [ 0.0708,  0.0252,  0.0738, -0.0070, -0.1183,  0.0771,  0.0143, -0.0578,\n",
      "         -0.0728, -0.0719, -0.1040, -0.0193, -0.0905,  0.0978,  0.1634, -0.0698,\n",
      "          0.1019,  0.0027,  0.0064, -0.1634,  0.0987, -0.0411,  0.1526, -0.0042,\n",
      "          0.0976, -0.0552,  0.0380,  0.1328,  0.0160,  0.0927, -0.0451, -0.1230]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.fc2.bias | Size: torch.Size([32]) | Values : tensor([0.0334, 0.0037], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.final_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.8393, 0.8133], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.2.final_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0335, 0.0304], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0831,  0.0149, -0.0737, -0.0291, -0.0021, -0.0256, -0.0287,  0.0084,\n",
      "          0.0541, -0.0308,  0.0005, -0.0293,  0.0144, -0.0333, -0.0588, -0.0319,\n",
      "          0.0328,  0.0608,  0.0446, -0.0504, -0.0239, -0.0124, -0.0859, -0.0230,\n",
      "         -0.0783, -0.0322, -0.0653,  0.0129, -0.0459, -0.0685,  0.0751, -0.0232],\n",
      "        [ 0.0831,  0.0596, -0.0036,  0.0373, -0.0173,  0.0487, -0.0062,  0.0396,\n",
      "         -0.0034, -0.0278, -0.0209,  0.0344,  0.0319,  0.0344, -0.0836, -0.0067,\n",
      "         -0.0011, -0.0009,  0.0171, -0.1368, -0.0303, -0.0435, -0.0811,  0.0483,\n",
      "         -0.0366,  0.0101, -0.1236, -0.0058, -0.0227, -0.0432,  0.0287, -0.0190]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([ 7.4463e-06, -6.5577e-06], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0341,  0.0173, -0.0241,  0.0418,  0.0119,  0.0965,  0.0725,  0.0279,\n",
      "         -0.0390,  0.0938,  0.0231,  0.0653,  0.0251,  0.0453,  0.0236,  0.0398,\n",
      "          0.0247, -0.0103,  0.0139, -0.1226, -0.0629, -0.0783, -0.0043,  0.0398,\n",
      "          0.0099,  0.0188, -0.0770, -0.0442, -0.0169, -0.0532,  0.0020, -0.0837],\n",
      "        [-0.0056,  0.0211, -0.0111,  0.0096, -0.0252,  0.0500, -0.0111,  0.0261,\n",
      "         -0.0296, -0.0083,  0.0249,  0.0184,  0.0298,  0.0398,  0.0221,  0.0182,\n",
      "         -0.0108, -0.0539,  0.0186, -0.0827,  0.0062, -0.0136,  0.0008, -0.0107,\n",
      "         -0.0060,  0.0163,  0.0010, -0.0148, -0.0053,  0.0102, -0.0111, -0.0441]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0170, -0.0053], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-6.0646e-02,  3.0197e-03,  5.5825e-02, -2.3649e-02, -4.8735e-02,\n",
      "         -6.5931e-03, -3.9398e-02, -1.3002e-02, -2.0843e-03, -1.3961e-01,\n",
      "         -4.2550e-02, -1.7350e-02, -3.8701e-02, -4.5790e-02, -3.5591e-02,\n",
      "         -5.7798e-02, -1.4941e-02,  3.0274e-02,  4.8692e-02,  8.9882e-02,\n",
      "          8.9458e-02,  1.5400e-01,  1.5442e-02,  1.0519e-01,  3.9159e-02,\n",
      "          2.7631e-02,  6.9625e-02,  4.1996e-02, -1.7524e-02,  2.8008e-02,\n",
      "          2.5360e-02,  4.1849e-02],\n",
      "        [ 9.9269e-02, -1.5186e-03, -2.1778e-02,  1.2371e-02, -6.9433e-02,\n",
      "         -1.4522e-04, -9.2297e-02, -4.9743e-02, -7.1103e-02,  2.3028e-02,\n",
      "         -2.2831e-02, -2.0502e-02,  1.0664e-01, -8.0159e-02, -1.0580e-01,\n",
      "         -1.1554e-01, -2.8362e-02, -3.6086e-02,  8.4723e-02, -6.1365e-02,\n",
      "          2.3240e-02,  4.7034e-02,  1.0001e-01, -8.3631e-02,  6.6204e-02,\n",
      "          8.4447e-02,  4.9867e-02,  6.2958e-02,  9.5166e-02, -4.3258e-02,\n",
      "          5.6068e-02, -6.6220e-03]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0142,  0.0871], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0188,  0.0425, -0.0235,  0.0363,  0.0550,  0.0239,  0.0367, -0.0692,\n",
      "         -0.0800,  0.0367, -0.0535,  0.0200,  0.0323,  0.0305,  0.0590, -0.0362,\n",
      "         -0.0083, -0.0385, -0.0294, -0.0366, -0.0268,  0.0052,  0.0389,  0.0508,\n",
      "          0.0232,  0.0415,  0.0162,  0.0262,  0.0049, -0.0119,  0.0296, -0.0388],\n",
      "        [ 0.0568, -0.0257,  0.0604, -0.0495, -0.0618,  0.0332, -0.0902,  0.0815,\n",
      "          0.0575, -0.0284,  0.0698,  0.0560, -0.0668, -0.0421,  0.0372, -0.0449,\n",
      "          0.0523,  0.0512,  0.0391, -0.0142,  0.0508, -0.0791,  0.0047, -0.0646,\n",
      "         -0.0207, -0.0728,  0.0383, -0.0820,  0.0553,  0.0315,  0.0029, -0.0953]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0219, 0.0064], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7767, 0.7958], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.self_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0266, 0.0104], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.fc1.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.1301, -0.0479,  0.0975, -0.2608,  0.1081, -0.1715, -0.0469, -0.0941,\n",
      "          0.1385, -0.1854, -0.0175, -0.0011, -0.0573,  0.0215,  0.0438,  0.0437,\n",
      "         -0.0996,  0.1436, -0.1270,  0.2138,  0.0351,  0.1109, -0.0665,  0.0302,\n",
      "         -0.0927, -0.1389, -0.0749, -0.0567,  0.0430, -0.0279,  0.0304,  0.0247],\n",
      "        [ 0.0836, -0.0425,  0.0235, -0.0661, -0.0158, -0.0584, -0.0400, -0.0290,\n",
      "          0.0087, -0.0699, -0.0300,  0.0056, -0.0061, -0.0063,  0.0199, -0.0595,\n",
      "          0.0363,  0.0294, -0.0423,  0.0187,  0.0399,  0.0802, -0.0111,  0.1082,\n",
      "          0.0210,  0.0189, -0.0137, -0.0102, -0.0318,  0.0236, -0.0004, -0.0741]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.fc1.bias | Size: torch.Size([32]) | Values : tensor([-0.0245, -0.0107], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.fc2.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.1526, -0.0339,  0.0381,  0.0665, -0.0276,  0.0842, -0.1435,  0.0333,\n",
      "         -0.0576, -0.0592,  0.0593, -0.1112,  0.0217,  0.1143, -0.0086,  0.1229,\n",
      "          0.0223,  0.0043,  0.0087, -0.1689, -0.0655,  0.1806, -0.0832,  0.0032,\n",
      "          0.1274, -0.0856,  0.1463,  0.1225, -0.0466,  0.0083,  0.0360,  0.0857],\n",
      "        [ 0.0446,  0.0011,  0.0688, -0.0631, -0.1139,  0.1118,  0.0316,  0.0295,\n",
      "         -0.1034, -0.0579, -0.0994, -0.1241,  0.0133, -0.0523, -0.0827, -0.0113,\n",
      "         -0.1798, -0.0890,  0.0935, -0.0208, -0.0816, -0.0230,  0.1392,  0.0865,\n",
      "          0.0274, -0.2493,  0.0332,  0.0317,  0.0576,  0.1529, -0.0692, -0.0572]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.fc2.bias | Size: torch.Size([32]) | Values : tensor([ 0.0283, -0.0078], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.final_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.8363, 0.8004], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layers.3.final_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([ 0.0271, -0.0334], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layernorm_embedding.weight | Size: torch.Size([32]) | Values : tensor([0.7325, 0.7337], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: encoder.layernorm_embedding.bias | Size: torch.Size([32]) | Values : tensor([ 0.0738, -0.0838], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.value_embedding.value_projection.weight | Size: torch.Size([32, 22]) | Values : tensor([[ 0.1108, -0.1371, -0.0422,  0.2093, -0.0094, -0.0026, -0.0059,  0.0199,\n",
      "          0.0130,  0.0022,  0.0125,  0.0097,  0.0332,  0.0061, -0.0027, -0.0068,\n",
      "         -0.5177, -0.4547,  0.0165,  0.1497, -0.2102,  0.1467],\n",
      "        [ 0.2033, -0.0225,  0.0686,  0.0352,  0.0171, -0.0189,  0.0029, -0.0079,\n",
      "         -0.0069, -0.0226,  0.0163,  0.0130,  0.0109, -0.0089, -0.0281,  0.0460,\n",
      "         -0.1850,  0.4374, -0.0097, -0.0224,  0.0474,  0.0433]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.embed_positions.weight | Size: torch.Size([6, 32]) | Values : tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00],\n",
      "        [8.4147e-01, 5.3317e-01, 3.1098e-01, 1.7689e-01, 9.9833e-02, 5.6204e-02,\n",
      "         3.1618e-02, 1.7782e-02, 9.9998e-03, 5.6234e-03, 3.1623e-03, 1.7783e-03,\n",
      "         1.0000e-03, 5.6234e-04, 3.1623e-04, 1.7783e-04, 5.4030e-01, 8.4601e-01,\n",
      "         9.5042e-01, 9.8423e-01, 9.9500e-01, 9.9842e-01, 9.9950e-01, 9.9984e-01,\n",
      "         9.9995e-01, 9.9998e-01, 9.9999e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00]]) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0157,  0.0348,  0.0250, -0.1789, -0.0060, -0.0251, -0.1648, -0.0083,\n",
      "          0.0126, -0.2043, -0.0990,  0.0462,  0.0036, -0.0715, -0.0744, -0.0525,\n",
      "         -0.1013,  0.0765,  0.0762,  0.1005,  0.0428,  0.1005,  0.0039, -0.0869,\n",
      "         -0.0598,  0.0319,  0.0556, -0.0341, -0.0418,  0.0612, -0.0924,  0.1224],\n",
      "        [-0.0354, -0.0559, -0.0109,  0.2269,  0.0303, -0.0123,  0.1695, -0.0118,\n",
      "         -0.0832,  0.1669,  0.0721, -0.0314, -0.0209,  0.0484,  0.0070,  0.0304,\n",
      "          0.0890, -0.0647, -0.0883, -0.0814, -0.0466, -0.0775,  0.0329,  0.0966,\n",
      "          0.0757, -0.0536, -0.0528,  0.0919,  0.0848, -0.0345,  0.0784, -0.1180]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0002,  0.0001], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 2.3922e-02,  1.6419e-02,  1.6173e-01, -2.9113e-02, -1.4351e-04,\n",
      "          8.5551e-03,  2.3758e-02,  6.3395e-02, -1.7980e-02, -6.0786e-02,\n",
      "         -1.4156e-01,  5.3005e-02, -3.6239e-03,  1.1896e-03,  2.4754e-02,\n",
      "          2.1700e-02, -2.1662e-02,  6.1357e-03, -1.0927e-02,  2.1229e-02,\n",
      "          7.1753e-02,  3.0882e-02, -1.2012e-01, -3.2235e-03, -2.2165e-02,\n",
      "          9.7906e-02,  2.6822e-02,  4.8355e-02, -1.1782e-02, -5.3054e-03,\n",
      "         -1.5132e-02, -1.4787e-02],\n",
      "        [-7.3206e-03,  1.9047e-02,  6.0022e-02, -5.3156e-02,  2.4401e-02,\n",
      "         -9.1471e-03,  1.7181e-02,  4.8165e-02,  6.3905e-03,  1.6859e-02,\n",
      "         -1.2883e-01,  6.1705e-02, -5.9723e-03,  9.6032e-04,  3.2067e-02,\n",
      "          1.2799e-01, -5.5211e-02, -3.3339e-03, -5.2139e-03,  2.2063e-02,\n",
      "          9.8961e-02,  1.0329e-01, -7.1683e-02, -1.7576e-02, -6.6527e-02,\n",
      "          2.0368e-02, -1.1903e-02,  6.1826e-02, -1.6526e-02, -3.0353e-02,\n",
      "         -5.1401e-02, -4.3769e-03]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0109,  0.0097], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0609,  0.1331, -0.2026, -0.1632,  0.1002,  0.1259, -0.1006,  0.1093,\n",
      "          0.0500, -0.0387,  0.1414,  0.1030,  0.0150, -0.0543,  0.1195,  0.1581,\n",
      "         -0.0170,  0.0554,  0.0653, -0.0346,  0.0171, -0.0842, -0.2037, -0.0796,\n",
      "         -0.0899, -0.1615, -0.0779, -0.0377, -0.0913, -0.0900, -0.1022, -0.0722],\n",
      "        [-0.0321, -0.2273,  0.1571,  0.1375, -0.0132, -0.1768,  0.1328, -0.0676,\n",
      "         -0.0942,  0.0174, -0.0380, -0.0931, -0.0304,  0.0298, -0.1830, -0.1153,\n",
      "          0.0337, -0.0832, -0.0663,  0.0985, -0.0896, -0.0027,  0.1951,  0.0766,\n",
      "          0.0642,  0.1502,  0.0910,  0.0236,  0.1165,  0.1777,  0.1153,  0.1048]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0647,  0.0608], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-2.6990e-02,  1.2546e-02,  5.6434e-02,  4.0542e-02, -8.2281e-02,\n",
      "          5.9112e-02, -7.9201e-02,  5.7187e-04,  4.6688e-02, -5.2814e-02,\n",
      "          9.2141e-02,  3.9135e-02,  4.4845e-03,  3.4276e-02,  2.1737e-02,\n",
      "          1.2450e-01, -5.7627e-02, -6.5416e-02,  1.0385e-01,  4.9735e-02,\n",
      "         -4.2121e-02,  8.2780e-02,  6.6809e-02,  4.4894e-02,  3.6736e-02,\n",
      "          2.9554e-02,  6.8702e-02, -1.2286e-01,  4.8341e-02, -4.5597e-02,\n",
      "         -1.2324e-01, -4.8882e-02],\n",
      "        [-8.8435e-03,  2.5637e-03,  1.3709e-01,  3.2211e-02, -5.3786e-02,\n",
      "          6.6101e-02, -6.1428e-02,  3.0846e-02,  6.9977e-02, -1.0120e-01,\n",
      "          6.9393e-02, -7.2373e-02, -5.7532e-03,  1.2195e-01, -1.7179e-03,\n",
      "          1.0400e-01, -1.0712e-01,  2.0447e-02,  8.4799e-02, -2.9355e-02,\n",
      "          1.3407e-02,  7.6195e-02,  6.9089e-02,  1.5541e-02, -1.0613e-04,\n",
      "          1.1130e-01, -3.5055e-02, -3.9194e-02,  6.9580e-02, -6.3176e-02,\n",
      "         -8.9156e-04,  3.6272e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0270, 0.0080], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7115, 0.7299], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.self_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([ 0.0605, -0.0170], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0857,  0.0061, -0.0298, -0.0101,  0.0666, -0.0360, -0.0173,  0.0327,\n",
      "          0.0765,  0.1272,  0.0810,  0.1102, -0.0495,  0.1135,  0.0817,  0.0022,\n",
      "          0.0026,  0.0296, -0.0586,  0.0050,  0.0211,  0.1168, -0.0341, -0.0207,\n",
      "         -0.0663, -0.1204, -0.0329, -0.0135, -0.0931, -0.0188, -0.0207,  0.0981],\n",
      "        [ 0.0216,  0.0215, -0.0953, -0.0389,  0.0795,  0.0171,  0.0242,  0.0550,\n",
      "          0.0149,  0.1503,  0.0398,  0.1798, -0.0568,  0.0303, -0.0303,  0.0265,\n",
      "          0.0434, -0.0132,  0.0095, -0.0312, -0.0360,  0.0365, -0.0254,  0.0514,\n",
      "         -0.0094, -0.0848, -0.1323, -0.0655, -0.0632, -0.0864,  0.0905,  0.0398]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0003, -0.0002], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0419,  0.0214,  0.0259,  0.0554,  0.0133, -0.0532, -0.0469, -0.0554,\n",
      "         -0.0089, -0.0012,  0.0162, -0.0312, -0.0225, -0.0193,  0.0029, -0.0542,\n",
      "         -0.0389, -0.0350, -0.0201,  0.0856,  0.0789,  0.0588, -0.0022,  0.0028,\n",
      "          0.0169, -0.0240,  0.0016,  0.0011,  0.0036,  0.0061,  0.0106,  0.1152],\n",
      "        [ 0.0011,  0.0276, -0.0125, -0.0102,  0.0023, -0.1183, -0.1003,  0.0107,\n",
      "          0.0102, -0.0291,  0.0121,  0.0742,  0.0097, -0.0007,  0.0119, -0.0347,\n",
      "         -0.0055,  0.0203, -0.0072,  0.0049,  0.0438,  0.1231, -0.0045, -0.0430,\n",
      "         -0.0453, -0.0125,  0.0318,  0.0633, -0.0225, -0.0207, -0.0104, -0.0183]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0011, 0.0172], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0145, -0.0532, -0.0264,  0.0416,  0.1077, -0.2108, -0.1726,  0.0389,\n",
      "         -0.0032, -0.1562, -0.0792,  0.0438,  0.0309, -0.1739, -0.0802,  0.0422,\n",
      "         -0.0608,  0.0200, -0.0791,  0.1565,  0.0087,  0.0089,  0.1815,  0.0272,\n",
      "          0.0330,  0.0454,  0.0504, -0.0074,  0.0394,  0.0895,  0.0925,  0.0979],\n",
      "        [-0.1937, -0.0743,  0.1911,  0.2165,  0.1133,  0.0627,  0.0644, -0.0706,\n",
      "         -0.0359, -0.0985, -0.0602, -0.1039, -0.0643, -0.1090, -0.0296, -0.1579,\n",
      "          0.1437, -0.1419, -0.1684, -0.0299, -0.0021,  0.1676,  0.1772,  0.1007,\n",
      "          0.0944,  0.2209,  0.1192,  0.0326,  0.0553,  0.1017,  0.0802,  0.0913]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0023, 0.0706], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0116, -0.1209, -0.0979, -0.0398, -0.1360,  0.1360,  0.0876, -0.1695,\n",
      "          0.1094,  0.0286,  0.1549, -0.1686, -0.1253, -0.0288, -0.0264,  0.1116,\n",
      "         -0.1113,  0.1224,  0.1062, -0.1551, -0.1116,  0.0805,  0.0702, -0.0689,\n",
      "          0.0589, -0.0834, -0.1422,  0.1436, -0.0807, -0.1494,  0.0960,  0.1444],\n",
      "        [-0.0281,  0.0346, -0.0167,  0.0101,  0.0154,  0.0136,  0.0394, -0.0120,\n",
      "          0.0126,  0.0154,  0.0683, -0.0193, -0.0532, -0.0120, -0.0158,  0.0234,\n",
      "          0.0423, -0.0003,  0.0061, -0.1199, -0.1178,  0.1076,  0.0252,  0.0166,\n",
      "          0.0151, -0.0957, -0.0857,  0.0810, -0.0407, -0.0969,  0.0812,  0.0680]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0452, -0.0105], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7374, 0.7254], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.encoder_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([ 0.0623, -0.0114], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.fc1.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 3.4497e-02, -1.3386e-03, -7.6171e-02, -1.7868e-02,  1.4095e-02,\n",
      "          9.9117e-03,  6.4571e-02, -5.3882e-02, -3.8833e-03, -5.3744e-02,\n",
      "         -3.3136e-02, -9.7041e-02, -2.6213e-02,  7.7109e-03,  1.8918e-02,\n",
      "         -1.2497e-01,  1.4984e-02,  4.1803e-02,  1.3325e-02,  3.3316e-02,\n",
      "          3.8616e-02,  1.1584e-01,  8.4311e-03, -2.2158e-05,  3.2561e-02,\n",
      "          8.2254e-02,  4.8268e-03,  1.9456e-02, -1.1793e-02, -5.5734e-02,\n",
      "         -2.5971e-03, -2.7247e-02],\n",
      "        [-3.6219e-02, -2.2338e-01,  1.4602e-02,  1.1116e-01,  1.2782e-01,\n",
      "         -5.1467e-02, -2.0923e-02, -1.0024e-02,  6.8656e-03,  5.2747e-03,\n",
      "          8.5807e-02,  9.0855e-03,  3.2431e-02, -5.8001e-02, -2.0123e-02,\n",
      "          5.0895e-02,  1.7368e-02,  1.3764e-02,  1.6798e-02,  3.4786e-02,\n",
      "         -1.2990e-01, -1.2825e-01,  1.1653e-01, -1.2142e-02,  1.9512e-02,\n",
      "         -4.5663e-02, -3.1273e-02,  4.6629e-03, -4.1076e-02, -4.7963e-03,\n",
      "          7.4224e-02,  2.2738e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.fc1.bias | Size: torch.Size([32]) | Values : tensor([ 0.0132, -0.0111], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.fc2.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0798,  0.0656,  0.1420,  0.0521,  0.0600,  0.0869,  0.1080,  0.1074,\n",
      "          0.0541,  0.1547,  0.1459,  0.1741,  0.0329,  0.1491,  0.1538,  0.0923,\n",
      "         -0.1564,  0.1847,  0.1408, -0.1488, -0.1395,  0.1929,  0.1053,  0.1147,\n",
      "         -0.1490,  0.1576,  0.2523, -0.1318,  0.1737,  0.1174,  0.1299,  0.1877],\n",
      "        [ 0.1916,  0.0496,  0.1087,  0.1375,  0.1182, -0.0108,  0.1809,  0.0616,\n",
      "          0.0083, -0.0180,  0.0219,  0.0410, -0.0419, -0.0015, -0.1055, -0.0034,\n",
      "         -0.0126, -0.0732,  0.0992,  0.0031,  0.0159,  0.0768,  0.1130, -0.0403,\n",
      "         -0.0051,  0.0849,  0.1021,  0.0429, -0.0197,  0.0107,  0.0688, -0.0360]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.fc2.bias | Size: torch.Size([32]) | Values : tensor([ 0.0075, -0.0163], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.final_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7434, 0.7779], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.0.final_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0840, 0.0008], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.1020,  0.0781,  0.0027,  0.1683, -0.1044, -0.0716, -0.0401, -0.1577,\n",
      "          0.0501,  0.3335, -0.0433, -0.2032,  0.0729,  0.0996,  0.0888, -0.0874,\n",
      "         -0.0396,  0.0474,  0.0257, -0.0401,  0.0440, -0.0606,  0.1105,  0.1466,\n",
      "          0.1142,  0.0418, -0.1312, -0.1198, -0.0706, -0.1281,  0.1385, -0.3541],\n",
      "        [-0.0484, -0.0357,  0.1714, -0.1819,  0.0433, -0.0257, -0.0966,  0.0947,\n",
      "         -0.0465, -0.2710,  0.0131,  0.0728, -0.0116, -0.1192, -0.0837, -0.0060,\n",
      "         -0.0232,  0.0196,  0.0016,  0.0129,  0.0280,  0.1076, -0.0594, -0.0686,\n",
      "         -0.0450,  0.0393,  0.0453,  0.1514,  0.0071,  0.0308, -0.0520,  0.2102]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0002,  0.0002], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0306,  0.0015, -0.0667,  0.0521, -0.0339,  0.0053,  0.0040, -0.0251,\n",
      "         -0.0334,  0.0146,  0.0349, -0.0247, -0.0283, -0.0082,  0.0297, -0.0305,\n",
      "          0.0045, -0.0055,  0.0593, -0.0173,  0.0109, -0.0146,  0.1432,  0.0646,\n",
      "          0.0327,  0.0190, -0.0551,  0.0653, -0.0004, -0.0519,  0.0059, -0.0160],\n",
      "        [ 0.0539,  0.0095, -0.0469, -0.0144, -0.0095, -0.0057, -0.0083,  0.0112,\n",
      "         -0.0243,  0.0542,  0.0962,  0.0243, -0.0433,  0.0575, -0.0061,  0.0009,\n",
      "         -0.0702,  0.0212,  0.0189, -0.0147, -0.1060, -0.0840,  0.0560,  0.0066,\n",
      "         -0.0108, -0.0615, -0.0185, -0.0592, -0.0077, -0.0245,  0.0043, -0.0239]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0107, -0.0057], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 1.7813e-02, -1.2192e-01,  6.9025e-01,  1.8886e-01, -1.6268e-01,\n",
      "         -5.5432e-02,  5.8807e-03, -1.8510e-01, -9.1967e-02,  1.7874e-01,\n",
      "         -2.7005e-01, -1.6786e-01,  2.8075e-02,  9.4855e-02, -1.0153e-01,\n",
      "         -3.6720e-01,  1.2266e-01, -8.2437e-02, -1.4152e-01, -3.5690e-01,\n",
      "          5.9942e-02,  2.7545e-01,  1.4088e-01,  3.3058e-02,  1.3390e-01,\n",
      "          1.0654e-01, -3.1365e-02,  2.7824e-01,  1.3593e-01, -3.2990e-02,\n",
      "          2.4011e-01, -5.9556e-02],\n",
      "        [ 1.5659e-01,  7.0563e-02, -2.3726e-01, -1.6413e-01,  4.5378e-02,\n",
      "          1.9430e-02,  1.7001e-02,  8.7732e-03,  2.3289e-01, -3.6383e-02,\n",
      "          8.6015e-02,  4.8283e-02,  6.1981e-02, -6.3756e-04,  1.4724e-01,\n",
      "          3.2121e-02, -1.4242e-01,  2.0895e-01,  1.3424e-01,  7.4966e-02,\n",
      "          7.7485e-02,  1.1235e-03, -9.9506e-02, -6.8445e-02, -1.5706e-01,\n",
      "          2.0048e-02, -1.7874e-01, -1.8121e-01, -2.1982e-01, -1.2070e-01,\n",
      "         -1.4770e-01, -1.2107e-01]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.1215, -0.1424], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0596, -0.0053, -0.0211, -0.0694, -0.0363,  0.0153, -0.0052, -0.0269,\n",
      "          0.0730,  0.0236, -0.0844,  0.0348, -0.0030, -0.0881, -0.0326, -0.0370,\n",
      "         -0.0363,  0.0079, -0.0163,  0.0320,  0.0311, -0.0482, -0.0146,  0.0132,\n",
      "          0.0561, -0.0253,  0.0828,  0.0273, -0.0110,  0.0039, -0.0195,  0.0314],\n",
      "        [-0.0026,  0.0015, -0.1393,  0.0148, -0.0141, -0.0370,  0.0201, -0.0466,\n",
      "          0.0779, -0.0329, -0.0161, -0.0104, -0.0505,  0.0407,  0.0040,  0.0311,\n",
      "          0.0754, -0.0219,  0.0411,  0.0194,  0.0518,  0.0282, -0.0429,  0.0192,\n",
      "          0.0222,  0.0011, -0.0043, -0.0128,  0.0297,  0.0208, -0.0109,  0.0246]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0002, -0.0085], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7145, 0.7185], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.self_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([ 0.0464, -0.0100], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0556,  0.0414, -0.0324,  0.0301, -0.0634,  0.0312, -0.0003,  0.0396,\n",
      "         -0.0045,  0.1043, -0.0363,  0.0991, -0.0015, -0.0228, -0.0223,  0.0076,\n",
      "         -0.0242, -0.0461,  0.0143, -0.0531, -0.0556,  0.0184,  0.0113,  0.0376,\n",
      "          0.0087, -0.0392, -0.0254,  0.0068, -0.0299, -0.0108,  0.0797, -0.0754],\n",
      "        [ 0.0016,  0.0769,  0.0125,  0.0933, -0.0261,  0.0746,  0.0308,  0.0732,\n",
      "         -0.0114,  0.1135, -0.0163,  0.1370,  0.0165,  0.0316, -0.0175,  0.0636,\n",
      "         -0.0698, -0.0835,  0.0034, -0.1239, -0.0500, -0.0131,  0.0360,  0.0049,\n",
      "          0.0340, -0.0271, -0.0477,  0.0050, -0.0314, -0.0178,  0.0536, -0.1111]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0003, 0.0005], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-5.9336e-02,  3.3761e-02,  8.0629e-03, -4.8863e-03,  8.9749e-03,\n",
      "         -1.5890e-01, -3.0949e-02, -1.4558e-02,  2.1729e-02, -2.3153e-04,\n",
      "         -3.4714e-02, -7.4705e-02, -4.3222e-02, -3.3560e-02,  1.0520e-02,\n",
      "          3.0820e-02, -2.5910e-02,  1.8508e-02, -3.5921e-02,  1.0590e-01,\n",
      "          4.7491e-02,  1.7845e-02, -3.8879e-04,  2.0339e-02,  3.3674e-02,\n",
      "         -6.8240e-03, -5.9046e-03, -2.1185e-02,  4.2447e-02,  3.8476e-02,\n",
      "         -3.0415e-03,  4.5592e-02],\n",
      "        [ 5.0211e-03,  2.2430e-02, -3.7958e-02, -4.0703e-02, -1.6933e-02,\n",
      "         -7.9499e-03,  1.0553e-01,  6.4529e-02,  2.0851e-03,  6.9340e-02,\n",
      "          8.2605e-03,  6.0886e-02, -4.0732e-02,  2.2745e-03, -3.9416e-05,\n",
      "          8.7655e-02, -1.8908e-03, -9.8710e-03,  9.0128e-03, -7.6115e-02,\n",
      "         -9.5100e-02, -3.5029e-02, -1.4445e-02,  2.7397e-02, -4.2691e-03,\n",
      "         -1.5149e-02, -4.3596e-02, -8.9208e-02, -5.8368e-02, -6.4492e-03,\n",
      "         -2.1409e-02, -9.3537e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0018, -0.0090], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.1403,  0.0698, -0.0716,  0.1228, -0.1172,  0.1115,  0.1381, -0.0570,\n",
      "         -0.0221,  0.0904,  0.1180, -0.1166, -0.0866,  0.0288,  0.0236, -0.1122,\n",
      "          0.0122, -0.0466, -0.0094, -0.2166, -0.0378, -0.0010,  0.0143,  0.0607,\n",
      "          0.0864,  0.0453,  0.0595,  0.0036,  0.0669,  0.0246,  0.0579, -0.0595],\n",
      "        [-0.1532,  0.0657, -0.0206,  0.0974, -0.1652,  0.0090, -0.0075, -0.0716,\n",
      "         -0.0192,  0.1753,  0.0326, -0.0833, -0.0723,  0.0556,  0.0420, -0.0481,\n",
      "         -0.0582, -0.0302,  0.0041, -0.1873,  0.0610,  0.0483,  0.0849,  0.0626,\n",
      "          0.0553,  0.0087,  0.0376, -0.0194,  0.0291, -0.0243,  0.0785, -0.0489]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([0.0524, 0.0383], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-6.0058e-02,  4.4670e-02, -7.6511e-02, -1.3097e-01,  1.5445e-02,\n",
      "         -6.6131e-02, -7.5823e-02,  4.4811e-02,  1.0767e-01,  4.1755e-02,\n",
      "          3.1298e-02,  9.4025e-02,  9.4391e-02,  9.0364e-02, -3.3360e-02,\n",
      "          6.4680e-02, -1.3713e-01, -5.4269e-02, -1.4936e-01,  1.8511e-02,\n",
      "         -8.6834e-02,  3.9133e-03,  3.9559e-02,  1.1733e-01,  1.0005e-01,\n",
      "          1.0584e-01,  1.5234e-01,  1.4727e-01,  1.4801e-01,  6.2195e-02,\n",
      "         -1.0937e-01,  9.8169e-02],\n",
      "        [-2.0046e-02, -3.5440e-03, -2.3151e-02,  8.5411e-04, -3.8949e-02,\n",
      "         -3.9104e-02, -1.1973e-02, -4.0596e-03,  1.7209e-02, -2.1225e-03,\n",
      "         -1.8961e-02,  2.9012e-02,  3.2128e-02,  8.1069e-02, -1.4333e-04,\n",
      "         -4.6891e-03, -2.0518e-02,  2.1619e-02, -1.8855e-02,  1.1738e-02,\n",
      "         -9.8697e-03,  3.9437e-02, -1.7894e-02,  5.2179e-02,  4.3663e-02,\n",
      "          2.4757e-02,  2.2064e-02,  3.4001e-02,  2.6609e-02,  2.8325e-03,\n",
      "         -1.3948e-02, -1.0762e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0358, -0.0055], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7296, 0.7172], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.encoder_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([ 0.0450, -0.0064], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.fc1.weight | Size: torch.Size([32, 32]) | Values : tensor([[-4.1240e-02,  4.0032e-02,  9.7273e-02, -3.3349e-02,  1.6231e-02,\n",
      "          6.0574e-02, -2.0520e-01, -1.3593e-02, -2.0900e-02, -1.7588e-02,\n",
      "         -1.0886e-01,  2.5736e-02,  2.2587e-02, -6.1470e-02,  1.1674e-01,\n",
      "          3.9409e-02, -3.7512e-02, -1.6514e-02,  6.7339e-02, -9.6378e-02,\n",
      "          2.3202e-01,  7.4830e-02, -3.4443e-02, -1.7578e-02, -2.0314e-02,\n",
      "          5.4042e-02, -2.7677e-01,  5.9239e-02, -1.5551e-02, -2.9471e-01,\n",
      "          1.9429e-02, -8.5151e-02],\n",
      "        [-4.0518e-02, -9.7938e-03, -1.3559e-03, -9.6890e-02,  1.6765e-02,\n",
      "         -1.6455e-02, -4.3884e-02,  3.9228e-02, -4.1483e-03, -1.6805e-01,\n",
      "          5.9906e-03,  5.2487e-02,  2.2079e-02, -1.4972e-02, -6.2896e-02,\n",
      "         -2.5754e-02, -7.6864e-02, -1.5261e-04,  6.2069e-02,  8.0439e-02,\n",
      "          3.3754e-02,  1.0309e-02,  7.4945e-02,  1.5361e-02, -2.1569e-02,\n",
      "          6.8175e-02,  4.2091e-02,  6.9184e-02,  2.8882e-02,  4.5436e-02,\n",
      "         -6.8131e-02,  6.5718e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.fc1.bias | Size: torch.Size([32]) | Values : tensor([-0.0321,  0.0003], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.fc2.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.1639, -0.0751,  0.1442,  0.0702,  0.1456,  0.1087,  0.1245, -0.4070,\n",
      "          0.0911,  0.0983,  0.0193,  0.0759,  0.0740, -0.3641,  0.0832, -0.0592,\n",
      "          0.0875,  0.0890,  0.0737,  0.0152,  0.0741,  0.1420,  0.1286,  0.1057,\n",
      "         -0.2459,  0.2497,  0.0411, -0.0789,  0.0528,  0.0277, -0.1966,  0.1034],\n",
      "        [ 0.1813, -0.0069, -0.0336, -0.0077,  0.0371,  0.1438,  0.0915, -0.3410,\n",
      "          0.0577,  0.1091,  0.0082, -0.0743,  0.1071, -0.2243,  0.0455,  0.0144,\n",
      "          0.0811,  0.1166,  0.0596, -0.0986,  0.0163,  0.0640, -0.0214,  0.0694,\n",
      "         -0.0105, -0.0181,  0.0868, -0.0312, -0.0039,  0.1051, -0.0965,  0.0229]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.fc2.bias | Size: torch.Size([32]) | Values : tensor([-0.0066, -0.0131], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.final_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7827, 0.8209], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.1.final_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0662, 0.0171], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0611, -0.0131, -0.2136, -0.0644,  0.1330, -0.1252, -0.0008,  0.1132,\n",
      "          0.0149,  0.0731,  0.1071,  0.1769, -0.0365, -0.1076,  0.0892,  0.1779,\n",
      "         -0.0178, -0.0500, -0.0101,  0.1399, -0.0671, -0.0848,  0.0513, -0.0726,\n",
      "         -0.0144, -0.1038,  0.1429, -0.0785, -0.0246,  0.2008, -0.0036,  0.0108],\n",
      "        [ 0.0033, -0.0579,  0.1900,  0.0757, -0.0035,  0.0689,  0.0280, -0.0257,\n",
      "         -0.0304,  0.0852, -0.0089, -0.0527,  0.1339,  0.0852, -0.0535, -0.0827,\n",
      "          0.0921, -0.0073, -0.0411, -0.1703,  0.0455,  0.0126, -0.0338,  0.0044,\n",
      "         -0.0493, -0.0298, -0.1634,  0.1171, -0.0070, -0.1887, -0.0034, -0.1483]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0002, -0.0003], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0194, -0.0066,  0.0694, -0.0730,  0.0129, -0.0190, -0.0428, -0.0090,\n",
      "          0.0163, -0.0734, -0.0488,  0.0150,  0.0508, -0.0397, -0.0424, -0.0114,\n",
      "          0.0172,  0.0365,  0.0315,  0.0343,  0.0456,  0.0849, -0.0832, -0.0114,\n",
      "         -0.0230,  0.0267,  0.0343,  0.0073,  0.0062,  0.0167,  0.0079,  0.0373],\n",
      "        [ 0.0043, -0.0273,  0.0200, -0.0277, -0.0061,  0.0326, -0.0323, -0.0315,\n",
      "          0.0054, -0.0827,  0.0072, -0.0928,  0.0157, -0.0120,  0.0222, -0.0392,\n",
      "          0.0103,  0.0167,  0.0492,  0.0552,  0.0369,  0.0544, -0.1572, -0.0043,\n",
      "         -0.0223, -0.0602, -0.0187,  0.0017, -0.0029, -0.0283, -0.0159,  0.0195]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0063,  0.0030], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.3060, -0.2146,  0.1687, -0.0787,  0.0748, -0.0349,  0.0137,  0.2293,\n",
      "          0.0334, -0.0217, -0.0645,  0.1622,  0.1523,  0.2560, -0.1367,  0.2028,\n",
      "         -0.0222,  0.0867,  0.0360,  0.0789,  0.0718, -0.1625,  0.0252, -0.1517,\n",
      "         -0.1715, -0.1057, -0.2012,  0.0988, -0.0476, -0.0541, -0.2208, -0.1132],\n",
      "        [-0.2814, -0.1309, -0.0554,  0.1584, -0.0373, -0.0935,  0.0469, -0.0538,\n",
      "         -0.0162,  0.0120,  0.1752, -0.0733, -0.1168, -0.1847, -0.1234, -0.0986,\n",
      "          0.0613, -0.1436, -0.1235,  0.0556, -0.3080, -0.0539,  0.1104,  0.1317,\n",
      "          0.2090,  0.0684,  0.3085, -0.0908,  0.0688,  0.3584,  0.1983,  0.2192]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.1041,  0.0991], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 6.4208e-02,  9.9398e-02, -6.2828e-02,  4.1851e-02, -2.0997e-03,\n",
      "         -2.0787e-02,  1.0663e-01, -6.9966e-03,  3.7758e-03, -7.5233e-03,\n",
      "          1.0582e-02, -2.4847e-05,  2.7513e-02,  2.3487e-02, -2.4910e-02,\n",
      "         -1.9638e-02, -2.6892e-02, -6.3231e-02, -7.7585e-03, -3.7598e-02,\n",
      "         -2.7756e-02,  1.2990e-02,  5.4836e-02,  5.6906e-02,  5.2652e-03,\n",
      "          1.7850e-02, -3.0012e-02, -2.0930e-03, -5.1499e-02, -2.1246e-02,\n",
      "          9.5078e-03, -7.8835e-03],\n",
      "        [ 1.3159e-03,  3.5105e-02, -1.9585e-02, -3.8405e-02,  3.9058e-02,\n",
      "          7.8151e-02,  1.2606e-02,  2.1065e-02,  3.8894e-02, -2.9359e-03,\n",
      "          2.1854e-02, -5.8981e-02, -1.3897e-02, -1.4809e-02, -1.5251e-02,\n",
      "         -1.7838e-03, -2.2224e-02, -3.9717e-02, -2.6971e-02, -4.3040e-02,\n",
      "          6.4108e-02,  1.1120e-02,  3.0928e-03,  1.7294e-02,  4.3871e-02,\n",
      "          2.8833e-02,  2.2837e-02, -2.7190e-02, -1.6926e-02,  2.8611e-03,\n",
      "         -5.9497e-03,  1.6950e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0094,  0.0059], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7075, 0.7768], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.self_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([ 0.0392, -0.0009], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0172, -0.0754, -0.0249, -0.0373, -0.0093, -0.0664, -0.0776, -0.0890,\n",
      "          0.0678, -0.1313,  0.1444, -0.1125,  0.0070,  0.0445,  0.0490, -0.0654,\n",
      "          0.0570,  0.0580,  0.0080,  0.1113,  0.1040, -0.0308, -0.0274,  0.0130,\n",
      "         -0.0090,  0.0246,  0.0911,  0.1034,  0.0484, -0.0316, -0.0430,  0.1026],\n",
      "        [-0.0047, -0.1156, -0.0362, -0.1100,  0.0762, -0.1726, -0.1224, -0.1772,\n",
      "          0.0729, -0.1789,  0.1400, -0.1514, -0.0171,  0.1054,  0.0797, -0.1877,\n",
      "          0.0845,  0.0994, -0.0758,  0.2371,  0.2251,  0.0190, -0.0070,  0.0213,\n",
      "          0.0165,  0.0070,  0.2470,  0.2494,  0.0171, -0.0288, -0.0521,  0.2520]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([ 2.9585e-04, -6.9082e-05], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0030,  0.0126,  0.0224,  0.0494,  0.0116,  0.1638,  0.1031,  0.0542,\n",
      "          0.0377,  0.0318,  0.0102,  0.0297,  0.0632,  0.0400,  0.0148,  0.0862,\n",
      "         -0.0263, -0.0011,  0.0136, -0.0571, -0.0852, -0.0488,  0.0084, -0.0091,\n",
      "          0.0271,  0.0061, -0.0156,  0.0025,  0.0159, -0.0121,  0.0009, -0.0791],\n",
      "        [-0.0187,  0.0271, -0.0303,  0.0096,  0.0121, -0.0100,  0.1710,  0.0469,\n",
      "         -0.0152,  0.0231, -0.0135, -0.0359, -0.0135, -0.0025,  0.0169,  0.1572,\n",
      "          0.0169,  0.0227,  0.0110, -0.0261, -0.1245, -0.1318,  0.0086,  0.0086,\n",
      "          0.0332,  0.0142, -0.0453, -0.0594, -0.0117,  0.0073,  0.0017, -0.0736]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0172, -0.0052], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.1385, -0.0424,  0.0268, -0.1163,  0.1392, -0.0280, -0.0195,  0.1250,\n",
      "          0.0317, -0.1164, -0.0152,  0.0988,  0.0553, -0.0111,  0.0161,  0.1033,\n",
      "          0.0462,  0.0199,  0.0018,  0.1859,  0.0164, -0.0776, -0.0416, -0.0235,\n",
      "         -0.0836, -0.0132, -0.0189, -0.0052, -0.0380,  0.0355, -0.0830,  0.0948],\n",
      "        [ 0.1279, -0.0178,  0.0350, -0.0918,  0.0881, -0.0820, -0.0664,  0.0889,\n",
      "          0.0182, -0.1701, -0.0527,  0.0929,  0.0277, -0.0377, -0.0732,  0.0741,\n",
      "         -0.0109,  0.0074,  0.0126,  0.2651,  0.0055, -0.0200, -0.0401, -0.0200,\n",
      "         -0.0608, -0.0308,  0.0066,  0.0340,  0.0217,  0.0895, -0.0865,  0.1309]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0473, -0.0227], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0822,  0.0741,  0.0107, -0.0163,  0.1180, -0.0241, -0.0424, -0.0786,\n",
      "          0.0644,  0.0341, -0.0005, -0.0880,  0.0914,  0.1288,  0.0935,  0.0759,\n",
      "          0.0807, -0.0470,  0.1086, -0.0244,  0.0285,  0.0618, -0.0396,  0.0057,\n",
      "         -0.0527,  0.0426, -0.0370, -0.0535, -0.0606, -0.1203, -0.0785, -0.0562],\n",
      "        [ 0.0895,  0.0058,  0.0425, -0.0700,  0.0095, -0.0141, -0.0601, -0.0139,\n",
      "         -0.0026, -0.0167, -0.0049,  0.0311,  0.0859,  0.0304,  0.0293,  0.0297,\n",
      "         -0.0055,  0.0175, -0.0018,  0.0265,  0.0447,  0.0302, -0.0098,  0.0685,\n",
      "          0.0008, -0.0052,  0.0052, -0.0105, -0.0493,  0.0332, -0.0658, -0.0145]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0246, -0.0070], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7152, 0.7766], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.encoder_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0401, 0.0010], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.fc1.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0115, -0.0528,  0.0016, -0.2510,  0.1156,  0.0025,  0.0044,  0.4690,\n",
      "         -0.0086, -0.2724, -0.0438,  0.5747,  0.0661, -0.0389, -0.0711,  0.3467,\n",
      "          0.0052, -0.0103,  0.0231,  0.1232, -0.0143, -0.1001, -0.0766, -0.2658,\n",
      "         -0.2525, -0.0398, -0.0067,  0.0374,  0.0482,  0.0380, -0.1492,  0.0774],\n",
      "        [ 0.0346,  0.0458,  0.0460,  0.0156,  0.0232,  0.0140, -0.0237, -0.0235,\n",
      "          0.0073, -0.0375, -0.0845, -0.0199, -0.0319, -0.0285,  0.0460, -0.0508,\n",
      "          0.0040, -0.0216, -0.0317, -0.0413,  0.1056,  0.1044, -0.0277,  0.0365,\n",
      "          0.0031,  0.0964,  0.0338,  0.0386, -0.0317,  0.0153, -0.0159, -0.0155]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.fc1.bias | Size: torch.Size([32]) | Values : tensor([-0.0034,  0.0213], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.fc2.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 1.9898e-01,  6.2338e-02,  1.5371e-01,  4.2860e-02,  1.8205e-01,\n",
      "          7.7178e-02,  8.7845e-02,  2.0252e-01, -1.4895e-01,  1.1724e-01,\n",
      "          2.7000e-02,  8.3433e-02, -4.3747e-01,  9.7261e-02,  2.5218e-02,\n",
      "         -1.7886e-02,  1.0812e-01, -9.6327e-02,  9.4625e-02,  2.2755e-01,\n",
      "          1.3103e-01,  5.1365e-02,  4.0145e-02, -1.2452e-01,  1.3895e-01,\n",
      "          1.2814e-01,  7.9950e-02,  4.5518e-02, -4.5042e-03,  1.6980e-01,\n",
      "         -8.2403e-02,  4.7555e-02],\n",
      "        [-1.7337e-02,  1.3428e-01, -2.2280e-02, -3.1550e-02,  1.5247e-02,\n",
      "          4.6248e-02, -3.6306e-02,  1.0506e-02, -1.3232e-01,  8.8138e-02,\n",
      "          7.5970e-02,  2.3289e-02, -1.3557e-01,  1.2075e-01,  1.1198e-01,\n",
      "         -2.4735e-05,  2.1133e-02,  8.2673e-02,  7.5288e-02,  2.1430e-01,\n",
      "         -1.9442e-01, -1.2746e-01, -1.7244e-02,  1.5840e-01, -5.8350e-02,\n",
      "          2.7280e-03, -2.0652e-02, -4.2356e-03,  7.9331e-02,  9.6152e-02,\n",
      "          1.8040e-02, -8.0477e-03]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.fc2.bias | Size: torch.Size([32]) | Values : tensor([-0.0308, -0.0016], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.final_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.8327, 0.8288], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.2.final_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0752, 0.0261], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0199,  0.0444,  0.0518, -0.0912,  0.0570, -0.0121, -0.0758, -0.1077,\n",
      "         -0.0760, -0.0175, -0.1113, -0.0916, -0.0362, -0.1214,  0.0231, -0.0933,\n",
      "         -0.0596,  0.0322,  0.0953, -0.0042,  0.1538,  0.1315, -0.0357,  0.1903,\n",
      "          0.1481, -0.1136, -0.0493,  0.1020, -0.0299, -0.1738,  0.1366, -0.0321],\n",
      "        [-0.0303, -0.0287, -0.1544,  0.0654, -0.0627,  0.0187,  0.1172,  0.1761,\n",
      "          0.0488,  0.0002,  0.1097,  0.1950, -0.0003,  0.1082, -0.0219,  0.1098,\n",
      "          0.0896, -0.0486, -0.0341,  0.0521, -0.2015, -0.1284, -0.0496, -0.1812,\n",
      "         -0.1528,  0.0656,  0.1010, -0.1423,  0.0585,  0.1713, -0.1659,  0.0550]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([ 3.3434e-05, -5.2458e-05], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0088, -0.0064, -0.0432,  0.0466, -0.0023,  0.0209,  0.0130,  0.0171,\n",
      "         -0.0086,  0.0717, -0.0011,  0.0035,  0.0006,  0.0197,  0.0506,  0.0224,\n",
      "          0.0363, -0.0131,  0.0019, -0.0602, -0.0074, -0.0368, -0.0458,  0.0028,\n",
      "          0.0299, -0.0198,  0.0015, -0.0114, -0.0099, -0.0423,  0.0394, -0.0496],\n",
      "        [ 0.0194, -0.0214,  0.0431,  0.0032,  0.0126,  0.0093, -0.0270, -0.0319,\n",
      "         -0.0168, -0.0760, -0.0237, -0.0348,  0.0283, -0.0273, -0.0273, -0.0411,\n",
      "         -0.0196,  0.0115,  0.0494,  0.0268,  0.0195,  0.0141, -0.0079,  0.0162,\n",
      "         -0.0291,  0.0050,  0.0042,  0.0763, -0.0244,  0.0491, -0.0460,  0.0733]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0017,  0.0086], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.1195,  0.0682,  0.0489, -0.0402, -0.0179,  0.0201, -0.0423,  0.0224,\n",
      "          0.1625,  0.0334, -0.0953,  0.0079,  0.0554,  0.0617,  0.0916,  0.0513,\n",
      "         -0.0758,  0.0841,  0.0758,  0.0390,  0.0565,  0.1157,  0.0390, -0.0359,\n",
      "         -0.0862,  0.0486, -0.1093, -0.1489, -0.1139, -0.1473,  0.0281, -0.1497],\n",
      "        [-0.1352, -0.1076, -0.0028,  0.0366,  0.0774, -0.0540,  0.0242,  0.0092,\n",
      "         -0.1582, -0.0980,  0.1325,  0.0170, -0.0933, -0.0684, -0.1231,  0.0062,\n",
      "          0.0492, -0.0578, -0.0739,  0.0404, -0.0395, -0.1487, -0.0135,  0.0360,\n",
      "          0.0556, -0.0785,  0.1100,  0.1325,  0.1457,  0.1851, -0.0503,  0.2243]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0610,  0.0438], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0251,  0.0110, -0.0378, -0.0030,  0.0339, -0.0185, -0.0523,  0.0133,\n",
      "         -0.0873, -0.0744, -0.0015,  0.0478, -0.0093,  0.0307,  0.0608, -0.0284,\n",
      "          0.0274, -0.0693, -0.0065, -0.0580,  0.0182,  0.0330, -0.0079,  0.0243,\n",
      "          0.0346,  0.0089,  0.0915,  0.0198, -0.0242, -0.0158, -0.0280,  0.0015],\n",
      "        [-0.0122,  0.0311, -0.0638, -0.0629, -0.0525, -0.0418, -0.0495,  0.0128,\n",
      "         -0.0169,  0.0198,  0.0452,  0.0015, -0.0163, -0.0033, -0.0118,  0.0307,\n",
      "         -0.0589,  0.0017, -0.0345, -0.0191,  0.0157,  0.0011,  0.0047,  0.0102,\n",
      "         -0.0484,  0.0209, -0.0002,  0.0104, -0.0102, -0.0076, -0.0366, -0.0174]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0270, -0.0008], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7264, 0.8292], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.self_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([ 0.0022, -0.0010], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn.k_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0306, -0.0780, -0.0193, -0.0390,  0.0664, -0.0377, -0.0258, -0.0465,\n",
      "          0.0135,  0.0086,  0.0202, -0.0573,  0.0529,  0.0609,  0.0933, -0.0673,\n",
      "          0.0664,  0.0497, -0.0363,  0.0772,  0.0620, -0.0815, -0.0174, -0.0511,\n",
      "          0.0112, -0.0433,  0.0066,  0.0754, -0.0135, -0.0457,  0.0172,  0.0597],\n",
      "        [ 0.0010, -0.0771, -0.0284, -0.0667,  0.0933, -0.0868, -0.0579, -0.0822,\n",
      "          0.0209, -0.0405, -0.0155, -0.0981,  0.0397,  0.0728,  0.0583, -0.1387,\n",
      "          0.0664,  0.0598, -0.0144,  0.1256,  0.0658, -0.0879, -0.0100, -0.0561,\n",
      "          0.0306, -0.0700,  0.0841,  0.1003,  0.0003, -0.0757,  0.0081,  0.0918]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn.k_proj.bias | Size: torch.Size([32]) | Values : tensor([ 0.0002, -0.0001], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn.v_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0162,  0.0387, -0.0031,  0.0304, -0.0084, -0.0357, -0.0936, -0.0447,\n",
      "         -0.0152, -0.0226, -0.0168, -0.0551, -0.0126,  0.0153,  0.0100, -0.0813,\n",
      "         -0.0013, -0.0079, -0.0239,  0.0388,  0.1057,  0.1138,  0.0097,  0.0114,\n",
      "         -0.0587, -0.0105,  0.0254, -0.0136, -0.0264, -0.0089,  0.0023,  0.0383],\n",
      "        [-0.0824,  0.0438, -0.0245,  0.0683,  0.0507, -0.0457, -0.0227,  0.0100,\n",
      "          0.0176,  0.0360,  0.0196, -0.0124, -0.0498,  0.0140,  0.0520, -0.0144,\n",
      "          0.0115, -0.0355, -0.0296,  0.0151,  0.0396,  0.0429, -0.0227,  0.0550,\n",
      "         -0.0009,  0.0006, -0.1046, -0.0522, -0.0393,  0.0080,  0.0094,  0.0305]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn.v_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0021, -0.0089], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn.q_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[ 0.0133, -0.0687, -0.0016, -0.0595,  0.0991,  0.0039, -0.0219,  0.0951,\n",
      "          0.0201, -0.0806, -0.0471,  0.0901,  0.0189,  0.0058, -0.0371,  0.0690,\n",
      "          0.0099,  0.0251,  0.0487,  0.1294, -0.0238, -0.0676, -0.0206, -0.0536,\n",
      "         -0.0642, -0.0363,  0.0245, -0.0339, -0.0128,  0.0335, -0.0749,  0.0753],\n",
      "        [ 0.0776, -0.0558,  0.0037, -0.1027,  0.0981, -0.0112, -0.0415,  0.0887,\n",
      "          0.0142, -0.1366,  0.0097,  0.1124,  0.0401, -0.0256, -0.0238,  0.1036,\n",
      "          0.0482, -0.0087, -0.0129,  0.1778, -0.0663, -0.1078, -0.0573, -0.0730,\n",
      "         -0.0833, -0.0414,  0.0434,  0.0073, -0.0176,  0.0721, -0.0844,  0.1441]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn.q_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0362, -0.0411], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn.out_proj.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0388, -0.0084,  0.0688,  0.0014,  0.1026, -0.0843, -0.0713, -0.0299,\n",
      "          0.0650,  0.0805, -0.0571, -0.1290, -0.0067, -0.0261,  0.0942,  0.0456,\n",
      "         -0.0655,  0.0579,  0.0894,  0.0421,  0.0391,  0.0960, -0.0686, -0.0660,\n",
      "          0.0820, -0.0889, -0.0772, -0.0487,  0.0818, -0.0329, -0.0468,  0.0410],\n",
      "        [ 0.0130, -0.0117, -0.0079,  0.0240,  0.0991,  0.0031, -0.0694, -0.0046,\n",
      "          0.0015,  0.0603,  0.0028, -0.0272,  0.0193, -0.0255, -0.0175,  0.0261,\n",
      "          0.0019, -0.0013, -0.0209, -0.0221, -0.0337,  0.0191, -0.0052,  0.0106,\n",
      "          0.0302, -0.0219, -0.0019,  0.0180,  0.0129,  0.0080, -0.0005,  0.0451]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn.out_proj.bias | Size: torch.Size([32]) | Values : tensor([-0.0130, -0.0091], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([0.7349, 0.8276], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.encoder_attn_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.0104, 0.0014], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.fc1.weight | Size: torch.Size([32, 32]) | Values : tensor([[-0.0884, -0.0774, -0.0089, -0.0596,  0.0123,  0.2719, -0.0853,  0.0344,\n",
      "          0.2772,  0.0179, -0.0427,  0.0437,  0.2718,  0.1655,  0.0393,  0.0275,\n",
      "         -0.2759,  0.3093,  0.3000, -0.0074, -0.0488,  0.0058,  0.0068, -0.1673,\n",
      "         -0.0648,  0.1073, -0.2748, -0.1475, -0.3561, -0.1145, -0.0292, -0.0619],\n",
      "        [-0.0526,  0.0509,  0.0185,  0.0273, -0.0089,  0.0162, -0.0467, -0.0773,\n",
      "          0.0089, -0.0138, -0.0259, -0.0769, -0.0045, -0.0451,  0.1439, -0.0126,\n",
      "         -0.0353,  0.0180,  0.0352, -0.0277,  0.0179,  0.1142,  0.0009,  0.0332,\n",
      "          0.0567,  0.0141,  0.0142, -0.0034, -0.0134, -0.0436,  0.0671, -0.0122]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.fc1.bias | Size: torch.Size([32]) | Values : tensor([-0.0077,  0.0079], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.fc2.weight | Size: torch.Size([32, 32]) | Values : tensor([[-5.5074e-01,  3.3839e-02, -6.3137e-04,  6.0154e-02, -6.5805e-02,\n",
      "         -6.6746e-02,  1.3066e-01,  9.4050e-03,  1.4278e-01,  3.9201e-02,\n",
      "          1.1624e-01, -5.9618e-02, -6.1421e-02,  1.0333e-01, -4.4939e-02,\n",
      "         -1.2536e-01,  2.8840e-02,  6.0218e-02,  2.4411e-01,  2.9586e-01,\n",
      "          1.0069e-01,  1.1322e-03,  8.9224e-02, -3.3684e-02,  2.3994e-01,\n",
      "          1.0336e-01, -9.2874e-02,  9.1736e-02, -1.1764e-01,  4.0844e-02,\n",
      "          7.5522e-02, -3.3652e-02],\n",
      "        [-1.2038e-01, -9.5477e-02,  2.7754e-02,  1.2834e-01, -1.3415e-02,\n",
      "         -2.0719e-02, -2.9413e-02, -7.8540e-03,  4.0047e-04,  2.6441e-02,\n",
      "          1.9504e-01,  7.1600e-02, -1.1740e-01,  1.2529e-01,  9.3551e-02,\n",
      "         -8.2503e-03,  3.4025e-02,  2.8675e-02,  1.4221e-01,  1.4334e-01,\n",
      "          1.6961e-02,  1.6149e-01,  2.2408e-01,  7.7719e-02,  6.4733e-02,\n",
      "          1.6369e-01, -2.4177e-02, -7.6843e-03,  5.6856e-02,  2.1079e-03,\n",
      "          1.0797e-01, -1.6030e-03]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.fc2.bias | Size: torch.Size([32]) | Values : tensor([-0.0411, -0.0044], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.final_layer_norm.weight | Size: torch.Size([32]) | Values : tensor([1.3483, 0.8434], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layers.3.final_layer_norm.bias | Size: torch.Size([32]) | Values : tensor([0.1257, 0.0632], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layernorm_embedding.weight | Size: torch.Size([32]) | Values : tensor([0.6835, 0.6758], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: decoder.layernorm_embedding.bias | Size: torch.Size([32]) | Values : tensor([0.1804, 0.0255], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:513: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming `model` is your Keras model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m plot_model(model, to_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_architecture.png\u001b[39m\u001b[38;5;124m'\u001b[39m, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py:45\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INFINITE \u001b[38;5;28;01mas\u001b[39;00m INFINITE_CARDINALITY\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DispatchServer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WorkerServer\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compression_ops\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoShardPolicy\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExternalStatePolicy\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m division\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[38;5;28;01mas\u001b[39;00m ged_ops\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompress\u001b[39m(element):\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwrapt\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nest\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_six\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse_tensor \u001b[38;5;28;01mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collections_abc \u001b[38;5;28;01mas\u001b[39;00m _collections_abc\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sorted\u001b[39m(dict_):\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m composite_tensor\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m op_callbacks\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:513\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    482\u001b[0m     _NP_TO_TF[pdt] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m    483\u001b[0m         _NP_TO_TF[dt] \u001b[38;5;28;01mfor\u001b[39;00m dt \u001b[38;5;129;01min\u001b[39;00m _NP_TO_TF \u001b[38;5;28;01mif\u001b[39;00m dt \u001b[38;5;241m==\u001b[39m pdt()\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    486\u001b[0m TF_VALUE_DTYPES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(_NP_TO_TF\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    489\u001b[0m _TF_TO_NP \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    490\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF:\n\u001b[0;32m    491\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m    492\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT:\n\u001b[0;32m    493\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    494\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE:\n\u001b[0;32m    495\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    496\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32:\n\u001b[0;32m    497\u001b[0m         np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[0;32m    498\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8:\n\u001b[0;32m    499\u001b[0m         np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[0;32m    500\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT16:\n\u001b[0;32m    501\u001b[0m         np\u001b[38;5;241m.\u001b[39muint16,\n\u001b[0;32m    502\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT32:\n\u001b[0;32m    503\u001b[0m         np\u001b[38;5;241m.\u001b[39muint32,\n\u001b[0;32m    504\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT64:\n\u001b[0;32m    505\u001b[0m         np\u001b[38;5;241m.\u001b[39muint64,\n\u001b[0;32m    506\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT16:\n\u001b[0;32m    507\u001b[0m         np\u001b[38;5;241m.\u001b[39mint16,\n\u001b[0;32m    508\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8:\n\u001b[0;32m    509\u001b[0m         np\u001b[38;5;241m.\u001b[39mint8,\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# NOTE(touts): For strings we use np.object as it supports variable length\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING:\n\u001b[1;32m--> 513\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject\u001b[49m,\n\u001b[0;32m    514\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX64:\n\u001b[0;32m    515\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex64,\n\u001b[0;32m    516\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128:\n\u001b[0;32m    517\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[0;32m    518\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64:\n\u001b[0;32m    519\u001b[0m         np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[0;32m    520\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL:\n\u001b[0;32m    521\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool,\n\u001b[0;32m    522\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT8:\n\u001b[0;32m    523\u001b[0m         _np_qint8,\n\u001b[0;32m    524\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT8:\n\u001b[0;32m    525\u001b[0m         _np_quint8,\n\u001b[0;32m    526\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT16:\n\u001b[0;32m    527\u001b[0m         _np_qint16,\n\u001b[0;32m    528\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT16:\n\u001b[0;32m    529\u001b[0m         _np_quint16,\n\u001b[0;32m    530\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT32:\n\u001b[0;32m    531\u001b[0m         _np_qint32,\n\u001b[0;32m    532\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BFLOAT16:\n\u001b[0;32m    533\u001b[0m         _np_bfloat16,\n\u001b[0;32m    534\u001b[0m \n\u001b[0;32m    535\u001b[0m     \u001b[38;5;66;03m# Ref types\u001b[39;00m\n\u001b[0;32m    536\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_HALF_REF:\n\u001b[0;32m    537\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m    538\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_FLOAT_REF:\n\u001b[0;32m    539\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[0;32m    540\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_DOUBLE_REF:\n\u001b[0;32m    541\u001b[0m         np\u001b[38;5;241m.\u001b[39mfloat64,\n\u001b[0;32m    542\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT32_REF:\n\u001b[0;32m    543\u001b[0m         np\u001b[38;5;241m.\u001b[39mint32,\n\u001b[0;32m    544\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT32_REF:\n\u001b[0;32m    545\u001b[0m         np\u001b[38;5;241m.\u001b[39muint32,\n\u001b[0;32m    546\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT8_REF:\n\u001b[0;32m    547\u001b[0m         np\u001b[38;5;241m.\u001b[39muint8,\n\u001b[0;32m    548\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT16_REF:\n\u001b[0;32m    549\u001b[0m         np\u001b[38;5;241m.\u001b[39muint16,\n\u001b[0;32m    550\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT16_REF:\n\u001b[0;32m    551\u001b[0m         np\u001b[38;5;241m.\u001b[39mint16,\n\u001b[0;32m    552\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT8_REF:\n\u001b[0;32m    553\u001b[0m         np\u001b[38;5;241m.\u001b[39mint8,\n\u001b[0;32m    554\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_STRING_REF:\n\u001b[0;32m    555\u001b[0m         np\u001b[38;5;241m.\u001b[39mobject,\n\u001b[0;32m    556\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX64_REF:\n\u001b[0;32m    557\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex64,\n\u001b[0;32m    558\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_COMPLEX128_REF:\n\u001b[0;32m    559\u001b[0m         np\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[0;32m    560\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_INT64_REF:\n\u001b[0;32m    561\u001b[0m         np\u001b[38;5;241m.\u001b[39mint64,\n\u001b[0;32m    562\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_UINT64_REF:\n\u001b[0;32m    563\u001b[0m         np\u001b[38;5;241m.\u001b[39muint64,\n\u001b[0;32m    564\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BOOL_REF:\n\u001b[0;32m    565\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool,\n\u001b[0;32m    566\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT8_REF:\n\u001b[0;32m    567\u001b[0m         _np_qint8,\n\u001b[0;32m    568\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT8_REF:\n\u001b[0;32m    569\u001b[0m         _np_quint8,\n\u001b[0;32m    570\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT16_REF:\n\u001b[0;32m    571\u001b[0m         _np_qint16,\n\u001b[0;32m    572\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QUINT16_REF:\n\u001b[0;32m    573\u001b[0m         _np_quint16,\n\u001b[0;32m    574\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_QINT32_REF:\n\u001b[0;32m    575\u001b[0m         _np_qint32,\n\u001b[0;32m    576\u001b[0m     types_pb2\u001b[38;5;241m.\u001b[39mDT_BFLOAT16_REF:\n\u001b[0;32m    577\u001b[0m         _np_bfloat16,\n\u001b[0;32m    578\u001b[0m }\n\u001b[0;32m    580\u001b[0m _QUANTIZED_DTYPES_NO_REF \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m([qint8, quint8, qint16, quint16, qint32])\n\u001b[0;32m    581\u001b[0m _QUANTIZED_DTYPES_REF \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(\n\u001b[0;32m    582\u001b[0m     [qint8_ref, quint8_ref, qint16_ref, quint16_ref, qint32_ref])\n",
      "File \u001b[1;32mc:\\Users\\sian_\\anaconda3\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Assuming `model` is your Keras model\n",
    "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
